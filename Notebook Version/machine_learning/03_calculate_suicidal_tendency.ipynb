{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from os import path\n",
    "print('Libraries imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(path.join(\"..\",\"data\", \"reddit_cleaned.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"megatext_clean\"] # inputs\n",
    "y = data[\"is_suicide\"] # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=70\n",
    "\n",
    "# 60 40\n",
    "# 70 30\n",
    "# 80 20\n",
    "# visualization\n",
    "# KNN\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amp', 'anymore', 'away', 'bad', 'best', 'better', 'care', 'college', 'come', 'country', 'dad', 'depressed', 'depression', 'die', 'end', 'exam', 'family', 'father', 'feel like', 'feeling', 'getting', 'girl', 'going', 'good', 'got', 'guy', 'ha', 'happy', 'hard', 'help', 'home', 'im', 'job', 'live', 'living', 'long', 'lot', 'love', 'make', 'mom', 'money', 'month', 'need', 'parent', 'people', 'person', 'point', 'problem', 'really', 'reason', 'said', 'say', 'school', 'shit', 'started', 'study', 'suicide', 'talk', 'tell', 'think', 'thought', 'told', 'tried', 'try', 'used', 'wanted', 'way', 'went', 'work', 'world']\n"
     ]
    }
   ],
   "source": [
    "tvec_optimised = TfidfVectorizer(\n",
    "    max_df=0.5, max_features=max_features, min_df=2, ngram_range=(1, 3), stop_words='english')\n",
    "X_train_tvec = tvec_optimised.fit_transform(X_train).todense()\n",
    "X_test_tvec = tvec_optimised.transform(X_test).todense()\n",
    "print(tvec_optimised.fit(X_train).get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvec_optimised = HashingVectorizer(\n",
    "    n_features=max_features, stop_words='english', alternate_sign=False)\n",
    "X_train_hvec = hvec_optimised.fit_transform(X_train).todense()\n",
    "X_test_hvec = hvec_optimised.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB + TFIDF\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tvec, y_train)\n",
    "taccuracy = mnb.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF + Hashing\n",
    "rfc = RandomForestClassifier(random_state=10)\n",
    "rfc.fit(X_train_hvec, y_train)\n",
    "haccuracy = rfc.score(X_test_hvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF + RF\n",
    "trfc = RandomForestClassifier(random_state=10)\n",
    "trfc.fit(X_train_tvec, y_train)\n",
    "trfcaccuracy = rfc.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing + Multinomial\n",
    "hmnb = MultinomialNB()\n",
    "hmnb.fit(X_train_tvec, y_train)\n",
    "hmnbaccuracy = hmnb.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer + MultinomialNB : 68.27586206896552\n",
      "HashingVectorizer + RandomForestClassifier : 60.0\n",
      "TfidfVectorizer + RandomForestClassifier : 52.41379310344828\n",
      "HashingVectorizer + MultinomialNB : 68.27586206896552\n"
     ]
    }
   ],
   "source": [
    "print(f\"TfidfVectorizer + MultinomialNB : {taccuracy * 100}\")\n",
    "print(f\"HashingVectorizer + RandomForestClassifier : {haccuracy * 100}\")\n",
    "print(f\"TfidfVectorizer + RandomForestClassifier : {trfcaccuracy * 100}\")\n",
    "print(f\"HashingVectorizer + MultinomialNB : {hmnbaccuracy * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
